"""Tests for the base chain streaming functionality with agent processing."""

import asyncio
import json
from unittest.mock import AsyncMock, MagicMock, patch, call
import pytest

from src.shared.base_agent import BaseAgent
from src.slices.base_chain import BaseChain


class MockAgent(BaseAgent):
    """Mock agent for testing."""
    
    def __init__(self, name):
        self._name = name
        self.on_request_calls = []
        self.on_response_calls = []
        self.on_response_stream_calls = []

    @property
    def name(self) -> str:
        return self._name

    async def on_request(self, request: dict) -> dict:
        self.on_request_calls.append(request)
        return request

    async def on_response(self, request: dict, response: dict) -> dict:
        self.on_response_calls.append((request, response))
        return response

    async def on_response_stream(self, request_context: dict, chunk: dict) -> None:
        self.on_response_stream_calls.append((request_context, chunk))


class MockRegistry:
    """Mock registry for testing."""
    
    def __init__(self):
        self.agents = {}

    def register_agent(self, agent):
        self.agents[agent.name] = agent

    def get_agent(self, name):
        return self.agents.get(name)


class MockBaseChain(BaseChain):
    """Mock BaseChain for testing."""
    
    def get_ollama_endpoint(self) -> str:
        return "/api/test"

    def prepare_context(self, request: dict) -> dict:
        return {
            "model": request.get("model", "test-model"),
            "prompt": request.get("prompt", "test-prompt"),
            "stream": request.get("stream", False)
        }

    def get_content_for_agent_parsing(self, request: dict) -> str:
        return request.get("prompt", "")

    def update_content_in_context(self, context: dict, cleaned_content: str):
        context["prompt"] = cleaned_content

    def build_ollama_request(self, context: dict) -> dict:
        return {
            "model": context["model"],
            "prompt": context["prompt"],
            "stream": context.get("stream", False)
        }

    def create_response_context(self, response_data: dict, agents: list) -> dict:
        return {
            "response": response_data,
            "agents": agents
        }

    def get_response_key(self) -> str:
        return "response"

    def get_content_path(self) -> list:
        return ["response"]

    def get_final_key(self) -> str:
        return "response"


@pytest.fixture
def mock_registry():
    """Create a mock registry."""
    return MockRegistry()


@pytest.fixture
def mock_chain(mock_registry):
    """Create a mock chain for testing."""
    return MockBaseChain(mock_registry)


@pytest.mark.asyncio
async def test_create_streaming_generator_processes_chunks(mock_chain):
    """Test that _create_streaming_generator processes individual chunks and calls agent on_response_stream."""
    # Create mock agents
    mock_agent = MockAgent("test")
    mock_chain.registry.agents[mock_agent.name] = mock_agent
    
    # Create mock response with streaming data
    async def mock_byte_stream():
        chunks = [
            b'{"response": "Hello"}',
            b'{"response": " World"}',
            b'{"response": "!"}',
            b'{"done": true}'
        ]
        for chunk in chunks:
            yield chunk
    
    mock_response = MagicMock()
    mock_response.aiter_bytes = MagicMock(return_value=mock_byte_stream())
    
    context = {"model": "test-model", "prompt": "test-prompt", "agents": ["test"]}
    agents_to_execute = ["test"]
    
    # Collect generated bytes
    collected_bytes = []
    async for byte_chunk in mock_chain._create_streaming_generator(mock_response, agents_to_execute, context):
        collected_bytes.append(byte_chunk)
    
    # Verify that original bytes were yielded
    expected_bytes = [
        b'{"response": "Hello"}',
        b'{"response": " World"}',
        b'{"response": "!"}',
        b'{"done": true}'
    ]
    assert collected_bytes == expected_bytes
    
    # Verify that agent on_response_stream was called for each chunk
    assert len(mock_agent.on_response_stream_calls) == 4
    expected_chunks = [
        {"response": "Hello"},
        {"response": " World"},
        {"response": "!"},
        {"done": True}
    ]
    for i, (req_context, chunk) in enumerate(mock_agent.on_response_stream_calls):
        assert req_context == context
        assert chunk == expected_chunks[i]


@pytest.mark.asyncio
async def test_create_streaming_generator_handles_json_parse_error(mock_chain):
    """Test that _create_streaming_generator handles JSON parsing errors gracefully."""
    # Create mock agents
    mock_agent = MockAgent("test")
    mock_chain.registry.agents[mock_agent.name] = mock_agent
    
    # Create mock response with invalid JSON
    async def mock_byte_stream():
        chunks = [
            b'{"response": "valid"}',
            b'invalid json',
            b'{"response": "after invalid"}'
        ]
        for chunk in chunks:
            yield chunk
    
    mock_response = MagicMock()
    mock_response.aiter_bytes = MagicMock(return_value=mock_byte_stream())
    
    context = {"model": "test-model", "prompt": "test-prompt", "agents": ["test"]}
    agents_to_execute = ["test"]
    
    # Collect generated bytes
    collected_bytes = []
    async for byte_chunk in mock_chain._create_streaming_generator(mock_response, agents_to_execute, context):
        collected_bytes.append(byte_chunk)
    
    # Verify that original bytes were yielded
    expected_bytes = [
        b'{"response": "valid"}',
        b'invalid json',
        b'{"response": "after invalid"}'
    ]
    assert collected_bytes == expected_bytes
    
    # Verify that agent on_response_stream was called only for valid JSON chunks
    assert len(mock_agent.on_response_stream_calls) == 2
    expected_chunks = [
        {"response": "valid"},
        {"response": "after invalid"}
    ]
    for i, (req_context, chunk) in enumerate(mock_agent.on_response_stream_calls):
        assert req_context == context
        assert chunk == expected_chunks[i]


@pytest.mark.asyncio
async def test_create_streaming_generator_aggregates_chunks_for_post_processing(mock_chain):
    """Test that _create_streaming_generator aggregates chunks for post-processing."""
    # Create mock agents
    mock_agent = MockAgent("test")
    mock_chain.registry.register_agent("test", mock_agent)
    
    # Create mock response with streaming data
    async def mock_byte_stream():
        chunks = [
            b'{"response": "Hello"}',
            b'{"response": " World"}',
            b'{"done": true}'
        ]
        for chunk in chunks:
            yield chunk
    
    mock_response = MagicMock()
    mock_response.aiter_bytes = MagicMock(return_value=mock_byte_stream())
    
    context = {"model": "test-model", "prompt": "test-prompt", "agents": ["test"]}
    agents_to_execute = ["test"]
    
    # Mock the execute agent chain on response to verify it gets called
    original_method = mock_chain._execute_agent_chain_on_response
    mock_chain._execute_agent_chain_on_response = AsyncMock(return_value={"response": "processed"})
    
    # Collect generated bytes
    collected_bytes = []
    async for byte_chunk in mock_chain._create_streaming_generator(mock_response, agents_to_execute, context):
        collected_bytes.append(byte_chunk)
    
    # Verify that post-processing was called
    mock_chain._execute_agent_chain_on_response.assert_called_once()
    
    # Check the call arguments
    call_args = mock_chain._execute_agent_chain_on_response.call_args
    assert call_args[0][0] == agents_to_execute  # agents
    assert call_args[0][1] == context  # request context
    # Check that response context contains aggregated response
    response_context = call_args[0][2]
    assert "response" in response_context
    aggregated_response = response_context["response"]
    # Should be aggregated from the chunks: "Hello" + " World" = "Hello World"
    assert aggregated_response["response"] == "Hello World"


@pytest.mark.asyncio
async def test_create_streaming_generator_handles_chat_format(mock_chain):
    """Test that _create_streaming_generator handles chat format responses."""
    # Create mock agents
    mock_agent = MockAgent("test")
    mock_chain.registry.register_agent("test", mock_agent)
    
    # Create mock response with chat format
    async def mock_byte_stream():
        chunks = [
            b'{"message": {"content": "Hello"}}',
            b'{"message": {"content": " World"}}',
            b'{"done": true}'
        ]
        for chunk in chunks:
            yield chunk
    
    mock_response = MagicMock()
    mock_response.aiter_bytes = MagicMock(return_value=mock_byte_stream())
    
    context = {"model": "test-model", "prompt": "test-prompt", "agents": ["test"]}
    agents_to_execute = ["test"]
    
    # Mock the execute agent chain on response to verify it gets called
    mock_chain._execute_agent_chain_on_response = AsyncMock(return_value={"response": "processed"})
    
    # Collect generated bytes
    collected_bytes = []
    async for byte_chunk in mock_chain._create_streaming_generator(mock_response, agents_to_execute, context):
        collected_bytes.append(byte_chunk)
    
    # Verify that post-processing was called with aggregated chat format
    mock_chain._execute_agent_chain_on_response.assert_called_once()
    call_args = mock_chain._execute_agent_chain_on_response.call_args
    response_context = call_args[0][2]
    aggregated_response = response_context["response"]
    # Should be aggregated from the chat chunks: "Hello" + " World" = "Hello World"
    assert aggregated_response["message"]["content"] == "Hello World"


@pytest.mark.asyncio
async def test_create_streaming_generator_agent_error_handling(mock_chain):
    """Test that agent errors during streaming don't break the stream."""
    # Create mock agent that raises an exception
    class ErrorAgent(BaseAgent):
        def __init__(self):
            self._name = "error"
        
        @property
        def name(self) -> str:
            return self._name
        
        async def on_request(self, request: dict) -> dict:
            return request
        
        async def on_response(self, request: dict, response: dict) -> dict:
            return response
        
        async def on_response_stream(self, request_context: dict, chunk: dict) -> None:
            raise Exception("Agent error")
    
    error_agent = ErrorAgent()
    mock_chain.registry.register_agent("error", error_agent)
    
    # Create mock response with streaming data
    async def mock_byte_stream():
        chunks = [
            b'{"response": "Hello"}',
            b'{"response": "World"}'
        ]
        for chunk in chunks:
            yield chunk
    
    mock_response = MagicMock()
    mock_response.aiter_bytes = MagicMock(return_value=mock_byte_stream())
    
    context = {"model": "test-model", "prompt": "test-prompt", "agents": ["error"]}
    agents_to_execute = ["error"]
    
    # Collect generated bytes - should still work despite agent errors
    collected_bytes = []
    async for byte_chunk in mock_chain._create_streaming_generator(mock_response, agents_to_execute, context):
        collected_bytes.append(byte_chunk)
    
    # Verify that original bytes were still yielded despite agent errors
    expected_bytes = [
        b'{"response": "Hello"}',
        b'{"response": "World"}'
    ]
    assert collected_bytes == expected_bytes


@pytest.mark.asyncio
async def test_aggregate_stream_chunks_generate_format():
    """Test aggregation of generate format chunks."""
    mock_registry = MockRegistry()
    mock_chain = MockBaseChain(mock_registry)
    
    chunks = [
        {"response": "Hello"},
        {"response": " World"},
        {"response": "!"},
        {"done": True}
    ]
    
    result = mock_chain._aggregate_stream_chunks(chunks)
    assert result["response"] == "Hello World!"
    assert result["done"] is True


@pytest.mark.asyncio
async def test_aggregate_stream_chunks_chat_format():
    """Test aggregation of chat format chunks."""
    mock_registry = MockRegistry()
    mock_chain = MockBaseChain(mock_registry)
    
    chunks = [
        {"message": {"content": "Hello"}},
        {"message": {"content": " World"}},
        {"message": {"content": "!"}},
        {"done": True}
    ]
    
    result = mock_chain._aggregate_stream_chunks(chunks)
    assert result["message"]["content"] == "Hello World!"
    assert result["done"] is True


@pytest.mark.asyncio
async def test_aggregate_stream_chunks_fallback_format():
    """Test aggregation fallback for unknown format."""
    mock_registry = MockRegistry()
    mock_chain = MockBaseChain(mock_registry)
    
    chunks = [
        {"unknown_field": "value1"},
        {"another_field": "value2"},
        {"final_field": "value3"}
    ]
    
    result = mock_chain._aggregate_stream_chunks(chunks)
    assert result == {"final_field": "value3"}  # Should return last chunk


@pytest.mark.asyncio
async def test_process_request_with_streaming_calls_create_streaming_generator(mock_chain):
    """Test that process_request with streaming=True calls _create_streaming_generator."""
    # Create mock agents
    mock_agent = MockAgent("test")
    mock_chain.registry.register_agent("test", mock_agent)
    
    # Mock the prepare_context to return streaming context
    original_prepare_context = mock_chain.prepare_context
    mock_chain.prepare_context = MagicMock(return_value={
        "model": "test-model",
        "prompt": "test-prompt",
        "stream": True,
        "agents": ["test"]
    })
    
    # Mock the httpx client and response
    with patch('httpx.AsyncClient') as mock_client_class:
        mock_client = MagicMock()
        mock_client_class.return_value.__aenter__.return_value = mock_client
        
        # Create mock response with streaming capability
        async def mock_byte_stream():
            yield b'{"response": "test"}'
        
        mock_resp = MagicMock()
        mock_resp.aiter_bytes = MagicMock(return_value=mock_byte_stream())
        mock_resp.status_code = 200
        mock_resp.headers = {}
        mock_client.post = AsyncMock(return_value=mock_resp)
        
        # Mock the build_ollama_request
        mock_chain.build_ollama_request = MagicMock(return_value={
            "model": "test-model",
            "prompt": "test-prompt",
            "stream": True
        })
        
        # Mock the create_response_context
        mock_chain.create_response_context = MagicMock(return_value={
            "response": {"response": "test"},
            "agents": ["test"]
        })
        
        # Process request with streaming
        request = {"model": "test-model", "prompt": "/test test-prompt", "stream": True}
        result = await mock_chain.process_request(request)
        
        # Verify that the result is a StreamingResponse
        from fastapi.responses import StreamingResponse
        assert isinstance(result, StreamingResponse)
        
        # The StreamingResponse should use our generator method
        # We can't directly check the generator, but we can verify the flow happened