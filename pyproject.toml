[build-system]
requires = ["setuptools", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "ollama-smart-proxy"
version = "0.1.0"
description = "A lightweight proxy server for Ollama that exposes OpenAI-compatible APIs"
requires-python = ">=3.12"
dependencies = [
    "fastapi>=0.113.0,<0.123.0",
    "httpx",
    "ollama",
    "pydantic-settings",
    "sqlalchemy",
    "uvicorn[standard]",
]

[project.optional-dependencies]
dev = [
    "black",
    "flake8",
    "pytest",
    "pytest-mock",
    "pytest-asyncio",
    "testcontainers>=4.0.0",
    "fastapi[all]",
    "httpx",
]
optimizer = [
    "psutil>=5.9.0",
]
rag = [
    "lightrag",
    "langgraph",
    "langchain",
    "pydantic",
    "neo4j",
    "psycopg2-binary",
    "requests",
]

[tool.black]
line-length = 88
target-version = ['py312']

[tool.flake8]
max-line-length = 88
extend-ignore = ["E203", "W503"]

[tool.pytest.ini_options]
testpaths = ["tests"]
pythonpath = ["."]
addopts = "--import-mode=importlib"
filterwarnings = [
    "ignore:The pynvml package is deprecated. Please install nvidia-ml-py instead:FutureWarning",
    "ignore:The @wait_container_is_ready decorator is deprecated:DeprecationWarning",
]